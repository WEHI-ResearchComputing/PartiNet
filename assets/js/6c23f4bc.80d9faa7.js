"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[644],{4940:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"training/training-output","title":"Training Output Reference","description":"This page describes the output generated during PartiNet training (both Step 1 and Step 2).","source":"@site/docs/training/training-output.md","sourceDirName":"training","slug":"/training/training-output","permalink":"/docs/training/training-output","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/training/training-output.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"3. Train Adaptive Router","permalink":"/docs/training/train2"}}');var t=i(4848),s=i(8453);const o={sidebar_position:4},a="Training Output Reference",l={},c=[{value:"Directory Structure",id:"directory-structure",level:2},{value:"Understanding Training Visualizations",id:"understanding-training-visualizations",level:2},{value:"Performance Curves",id:"performance-curves",level:3},{value:"Learning Rate Plot (<code>LR.png</code>)",id:"learning-rate-plot-lrpng",level:4},{value:"Results Plot (<code>results.png</code>)",id:"results-plot-resultspng",level:4},{value:"Evaluation Metrics",id:"evaluation-metrics",level:3},{value:"Confusion Matrix (<code>confusion_matrix.png</code>)",id:"confusion-matrix-confusion_matrixpng",level:4},{value:"Precision-Recall Curves",id:"precision-recall-curves",level:4},{value:"Batch Visualizations",id:"batch-visualizations",level:3},{value:"Training Batches (<code>train_batch*.jpg</code>)",id:"training-batches-train_batchjpg",level:4},{value:"Validation Results",id:"validation-results",level:4},{value:"Monitoring Training Progress",id:"monitoring-training-progress",level:2},{value:"Resuming Interrupted Training",id:"resuming-interrupted-training",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"training-output-reference",children:"Training Output Reference"})}),"\n",(0,t.jsx)(n.p,{children:"This page describes the output generated during PartiNet training (both Step 1 and Step 2)."}),"\n",(0,t.jsx)(n.h2,{id:"directory-structure",children:"Directory Structure"}),"\n",(0,t.jsxs)(n.p,{children:["PartiNet creates a new experiment directory (",(0,t.jsx)(n.code,{children:"exp"}),", ",(0,t.jsx)(n.code,{children:"exp2"}),", ",(0,t.jsx)(n.code,{children:"exp3"}),", etc.) within your project folder for each training run. The experiment number automatically increments to avoid overwriting previous runs."]}),"\n",(0,t.jsxs)(n.p,{children:["A ",(0,t.jsx)(n.strong,{children:"completed"})," training run will produce the following structure:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"project_folder/\r\n\u2514\u2500\u2500 exp*/\r\n    \u251c\u2500\u2500 cfg.yaml                      # Configuration parameters\r\n    \u251c\u2500\u2500 hyp.yaml                      # Hyperparameters used\r\n    \u251c\u2500\u2500 opt.yaml                      # Optimizer settings\r\n    \u251c\u2500\u2500 LR.png                        # Learning rate schedule plot\r\n    \u251c\u2500\u2500 results.png                   # Training/validation metrics over time\r\n    \u251c\u2500\u2500 results.txt                   # Metrics in text format\r\n    \u251c\u2500\u2500 confusion_matrix.png          # Model confusion matrix\r\n    \u251c\u2500\u2500 F1_curve.png                  # F1 score curve\r\n    \u251c\u2500\u2500 P_curve.png                   # Precision curve\r\n    \u251c\u2500\u2500 R_curve.png                   # Recall curve\r\n    \u251c\u2500\u2500 PR_curve.png                  # Precision-Recall curve\r\n    \u251c\u2500\u2500 train_batch*.jpg              # Training batch visualizations\r\n    \u251c\u2500\u2500 test_batch*_labels.jpg        # Validation ground truth\r\n    \u251c\u2500\u2500 test_batch*_pred.jpg          # Validation predictions\r\n    \u251c\u2500\u2500 events.out.tfevents.*         # TensorBoard logs\r\n    \u2514\u2500\u2500 weights/\r\n        \u251c\u2500\u2500 best.pt                   # Best checkpoint (by validation metric)\r\n        \u251c\u2500\u2500 last.pt                   # Most recent checkpoint\r\n        \u2514\u2500\u2500 epoch_*.pt                # Checkpoint for each epoch\n"})}),"\n",(0,t.jsx)(n.h2,{id:"understanding-training-visualizations",children:"Understanding Training Visualizations"}),"\n",(0,t.jsxs)(n.p,{children:["PartiNet generates several plots to help you evaluate model performance and training progress. You may find more in-depth guides of interpreting this data at ",(0,t.jsx)(n.a,{href:"https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc",children:"https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc"})," and ",(0,t.jsx)(n.a,{href:"https://docs.ultralytics.com/guides/yolo-performance-metrics/",children:"https://docs.ultralytics.com/guides/yolo-performance-metrics/"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Below is a quick guide for intepreting PartiNet training outputs:"}),"\n",(0,t.jsx)(n.h3,{id:"performance-curves",children:"Performance Curves"}),"\n",(0,t.jsxs)(n.h4,{id:"learning-rate-plot-lrpng",children:["Learning Rate Plot (",(0,t.jsx)(n.code,{children:"LR.png"}),")"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Shows the learning rate schedule over training epochs"}),"\n",(0,t.jsx)(n.li,{children:"Helps verify if learning rate warmup and decay are working as expected"}),"\n",(0,t.jsx)(n.li,{children:"Look for: smooth warmup period followed by gradual decay"}),"\n"]}),"\n",(0,t.jsxs)(n.h4,{id:"results-plot-resultspng",children:["Results Plot (",(0,t.jsx)(n.code,{children:"results.png"}),")"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Displays training metrics over time:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Box loss: measures how well the model predicts particle bounding boxes"}),"\n",(0,t.jsx)(n.li,{children:"Objectness loss: indicates model's confidence in particle detection"}),"\n",(0,t.jsx)(n.li,{children:"Classification loss: not used in particle picking (always 0)"}),"\n",(0,t.jsx)(n.li,{children:"Precision and recall on validation set"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Look for: steadily decreasing losses and improving precision/recall"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"evaluation-metrics",children:"Evaluation Metrics"}),"\n",(0,t.jsxs)(n.h4,{id:"confusion-matrix-confusion_matrixpng",children:["Confusion Matrix (",(0,t.jsx)(n.code,{children:"confusion_matrix.png"}),")"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"In particle picking, this is simplified since we only have one class"}),"\n",(0,t.jsx)(n.li,{children:"Shows true positives, false positives, and false negatives"}),"\n",(0,t.jsxs)(n.li,{children:["Useful for understanding if model is:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Missing particles (false negatives)"}),"\n",(0,t.jsx)(n.li,{children:"Making spurious detections (false positives)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"precision-recall-curves",children:"Precision-Recall Curves"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"PR Curve"})," (",(0,t.jsx)(n.code,{children:"PR_curve.png"}),"): Shows the tradeoff between precision and recall"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"X-axis: Recall (percentage of actual particles detected)"}),"\n",(0,t.jsx)(n.li,{children:"Y-axis: Precision (percentage of detections that are actual particles)"}),"\n",(0,t.jsx)(n.li,{children:"Look for: curve that stays high (closer to 1.0) across different confidence thresholds"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"P Curve"})," (",(0,t.jsx)(n.code,{children:"P_curve.png"}),"): Precision at different confidence thresholds"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Higher curve indicates better precision across thresholds"}),"\n",(0,t.jsx)(n.li,{children:"Use to choose confidence threshold for inference"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"R Curve"})," (",(0,t.jsx)(n.code,{children:"R_curve.png"}),"): Recall at different confidence thresholds"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Shows how many particles are detected as threshold varies"}),"\n",(0,t.jsx)(n.li,{children:"Helps balance between missing particles and false positives"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"F1 Curve"})," (",(0,t.jsx)(n.code,{children:"F1_curve.png"}),"): Harmonic mean of precision and recall"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Single metric combining precision and recall"}),"\n",(0,t.jsx)(n.li,{children:"Peak indicates optimal confidence threshold for balanced performance"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"batch-visualizations",children:"Batch Visualizations"}),"\n",(0,t.jsxs)(n.h4,{id:"training-batches-train_batchjpg",children:["Training Batches (",(0,t.jsx)(n.code,{children:"train_batch*.jpg"}),")"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Shows model predictions on training data in a mosaic of image augmentations"}),"\n",(0,t.jsx)(n.li,{children:"Blue boxes: Ground truth particle positions"}),"\n",(0,t.jsxs)(n.li,{children:["Look for:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Correct bounding boxes around particles even after image augmentation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"validation-results",children:"Validation Results"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"test_batch*_labels.jpg"}),": Ground truth annotations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"test_batch*_pred.jpg"}),": Model predictions on same images"]}),"\n",(0,t.jsx)(n.li,{children:"Compare these to assess model performance qualitatively"}),"\n",(0,t.jsxs)(n.li,{children:["Look for:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Consistent detection of obvious particles"}),"\n",(0,t.jsx)(n.li,{children:"Few spurious detections in background areas"}),"\n",(0,t.jsx)(n.li,{children:"Good handling of challenging cases (overlapping particles, varying contrast)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"monitoring-training-progress",children:"Monitoring Training Progress"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Real-time monitoring with TensorBoard:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"tensorboard --logdir /data/your_project_folder\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Then open your browser to ",(0,t.jsx)(n.code,{children:"http://localhost:6006"})," to view training metrics in real-time."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Incomplete training runs"})," (due to timeout or errors) will have fewer outputs - only configuration files, learning rate plots, and training batch visualizations. Validation plots and test predictions only appear when training completes successfully."]}),"\n",(0,t.jsx)(n.h2,{id:"resuming-interrupted-training",children:"Resuming Interrupted Training"}),"\n",(0,t.jsxs)(n.p,{children:["If training is interrupted due to timeout or out-of-memory errors, you can resume from the last checkpoint by pointing the ",(0,t.jsx)(n.code,{children:"--weight"})," parameter to the ",(0,t.jsx)(n.code,{children:"last.pt"})," file in your most recent experiment folder."]}),"\n",(0,t.jsx)(n.admonition,{title:"Which Checkpoint to Use?",type:"info",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"best.pt"})," typically represents the checkpoint with the best validation performance, whereas ",(0,t.jsx)(n.code,{children:"last.pt"})," contains weights for the last epoch, regardless of validation performance. ",(0,t.jsx)(n.strong,{children:"Overfitting of weights may occur with too many epochs of training"}),". This means ",(0,t.jsx)(n.code,{children:"last.pt"})," may actually have worse performance than ",(0,t.jsx)(n.code,{children:"best.pt"}),". It is important that you directly review validation performance during training to avoid this scenario"]})}),"\n",(0,t.jsx)(n.admonition,{title:"Advanced Users",type:"tip",children:(0,t.jsxs)(n.p,{children:["The YAML configuration files (",(0,t.jsx)(n.code,{children:"cfg.yaml"}),", ",(0,t.jsx)(n.code,{children:"hyp.yaml"}),", ",(0,t.jsx)(n.code,{children:"opt.yaml"}),") contain detailed information about the parameters and hyperparameters used during training. These can be useful for reproducing experiments or debugging training runs."]})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var r=i(6540);const t={},s=r.createContext(t);function o(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);